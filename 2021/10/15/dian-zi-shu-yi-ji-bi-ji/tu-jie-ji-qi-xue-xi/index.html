<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="图解机器学习算法作者：秋庭伸也 Python:3.7 scikit-learn:0.20.3 机器学习  有监督学习 分类(二元分类、多元分类）：逻辑回归， 支持向量机 ，支持向量机（核方法），朴素贝叶斯，随机森林，神经网络，KNN 回归：线性回归，正则化，支持向量机，支持向量机（核方法），随机森林，神经网络，KNN   无监督学习 降维：PCA、LSA、NMF、LDA、LLE、t-SNE 聚类：">
<meta property="og:type" content="article">
<meta property="og:title" content="读书笔记|图解机器学习算法">
<meta property="og:url" content="http://example.com/2021/10/15/dian-zi-shu-yi-ji-bi-ji/tu-jie-ji-qi-xue-xi/index.html">
<meta property="og:site_name" content="前程似锦，一路繁华">
<meta property="og:description" content="图解机器学习算法作者：秋庭伸也 Python:3.7 scikit-learn:0.20.3 机器学习  有监督学习 分类(二元分类、多元分类）：逻辑回归， 支持向量机 ，支持向量机（核方法），朴素贝叶斯，随机森林，神经网络，KNN 回归：线性回归，正则化，支持向量机，支持向量机（核方法），随机森林，神经网络，KNN   无监督学习 降维：PCA、LSA、NMF、LDA、LLE、t-SNE 聚类：">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-10-15T08:31:01.000Z">
<meta property="article:modified_time" content="2021-11-01T08:42:32.559Z">
<meta property="article:author" content="fanko">
<meta property="article:tag" content="读书笔记">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2021/10/15/dian-zi-shu-yi-ji-bi-ji/tu-jie-ji-qi-xue-xi/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2021/10/15/dian-zi-shu-yi-ji-bi-ji/tu-jie-ji-qi-xue-xi/","path":"2021/10/15/dian-zi-shu-yi-ji-bi-ji/tu-jie-ji-qi-xue-xi/","title":"读书笔记|图解机器学习算法"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>读书笔记|图解机器学习算法 | 前程似锦，一路繁华</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">前程似锦，一路繁华</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">坚持,努力,认真</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%BE%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95"><span class="nav-number">1.</span> <span class="nav-text">图解机器学习算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80"><span class="nav-number">1.1.</span> <span class="nav-text">基础</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9B%BE%E5%9E%8B%E7%BB%98%E5%88%B6"><span class="nav-number">1.1.0.0.1.</span> <span class="nav-text">图型绘制</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#pandas"><span class="nav-number">1.1.0.0.2.</span> <span class="nav-text">pandas</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.2.</span> <span class="nav-text">有监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">1.2.1.</span> <span class="nav-text">线性回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">1.2.2.</span> <span class="nav-text">正则化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-number">1.2.3.</span> <span class="nav-text">逻辑回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-number">1.2.4.</span> <span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E6%A0%B8%E6%96%B9%E6%B3%95%EF%BC%89SVC"><span class="nav-number">1.2.5.</span> <span class="nav-text">支持向量机（核方法）SVC</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="nav-number">1.2.6.</span> <span class="nav-text">朴素贝叶斯</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="nav-number">1.2.7.</span> <span class="nav-text">随机森林</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="nav-number">1.2.7.0.1.</span> <span class="nav-text">决策树</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97-1"><span class="nav-number">1.2.7.0.2.</span> <span class="nav-text">随机森林</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E5%BA%A6"><span class="nav-number">1.2.7.0.3.</span> <span class="nav-text">特征重要度</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">1.2.8.</span> <span class="nav-text">神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="nav-number">1.2.8.0.1.</span> <span class="nav-text">简单感知机</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Early-Stopping"><span class="nav-number">1.2.8.0.2.</span> <span class="nav-text">Early Stopping</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KNN%EF%BC%88K%E8%BF%91%E9%82%BB%EF%BC%89"><span class="nav-number">1.2.9.</span> <span class="nav-text">KNN（K近邻）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.3.</span> <span class="nav-text">无监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#PCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90"><span class="nav-number">1.3.1.</span> <span class="nav-text">PCA主成分分析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B9%E5%90%91"><span class="nav-number">1.3.1.0.1.</span> <span class="nav-text">方向</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%87%8D%E8%A6%81%E5%BA%A6"><span class="nav-number">1.3.1.0.2.</span> <span class="nav-text">重要度</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%BE%97%E5%88%86"><span class="nav-number">1.3.1.0.3.</span> <span class="nav-text">主成分得分</span></a></li><li class="nav-item nav-level-5"><a class="nav-link"><span class="nav-number">1.3.1.0.4.</span> <span class="nav-text"></span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LSA%E6%BD%9C%E5%9C%A8%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%EF%BC%88LSI%EF%BC%89"><span class="nav-number">1.3.2.</span> <span class="nav-text">LSA潜在语义分析（LSI）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NMF%E9%9D%9E%E8%B4%9F%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3"><span class="nav-number">1.3.3.</span> <span class="nav-text">NMF非负矩阵分解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LDA%E9%9A%90%E5%90%AB%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E5%B8%83"><span class="nav-number">1.3.4.</span> <span class="nav-text">LDA隐含狄利克雷分布</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#LDA%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4"><span class="nav-number">1.3.4.0.1.</span> <span class="nav-text">LDA算法步骤</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-means%E7%AE%97%E6%B3%95"><span class="nav-number">1.3.5.</span> <span class="nav-text">K-means算法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Elbow%E6%96%B9%E6%B3%95"><span class="nav-number">1.3.5.0.1.</span> <span class="nav-text">Elbow方法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B0%87%E5%86%85%E5%B9%B3%E6%96%B9%E5%92%8CWCSS"><span class="nav-number">1.3.5.0.2.</span> <span class="nav-text">簇内平方和WCSS</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83"><span class="nav-number">1.3.6.</span> <span class="nav-text">混合高斯分布</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83"><span class="nav-number">1.3.6.0.1.</span> <span class="nav-text">高斯分布</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LLE%E5%B1%80%E9%83%A8%E7%BA%BF%E6%80%A7%E5%B5%8C%E5%85%A5"><span class="nav-number">1.3.7.</span> <span class="nav-text">LLE局部线性嵌入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#t-SNE-t%E5%88%86%E5%B8%83%E9%9A%8F%E6%9C%BA%E9%82%BB%E5%9F%9F%E5%B5%8C%E5%85%A5"><span class="nav-number">1.3.8.</span> <span class="nav-text">t-SNE t分布随机邻域嵌入</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95%E5%92%8C%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-number">1.4.</span> <span class="nav-text">评估方法和各种数据处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="nav-number">1.4.1.</span> <span class="nav-text">分类问题评估方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="nav-number">1.4.2.</span> <span class="nav-text">回归问题评估方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88"><span class="nav-number">1.4.3.</span> <span class="nav-text">防止过拟合</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">1.4.3.0.1.</span> <span class="nav-text">交叉验证</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%90%9C%E7%B4%A2%E8%B6%85%E5%8F%82%E6%95%B0"><span class="nav-number">1.4.3.0.2.</span> <span class="nav-text">搜索超参数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-number">1.4.4.</span> <span class="nav-text">文本数据处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-number">1.4.5.</span> <span class="nav-text">图像数据处理</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="fanko"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">fanko</p>
  <div class="site-description" itemprop="description">-------- 济南大学17级本科生 --------大连理工大学21级研究生</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">186</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">47</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fankoyu2019" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fankoyu2019" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1402704510@qq.com" title="E-Mail → mailto:1402704510@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/15/dian-zi-shu-yi-ji-bi-ji/tu-jie-ji-qi-xue-xi/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="fanko">
      <meta itemprop="description" content="-------- 济南大学17级本科生 --------大连理工大学21级研究生">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="前程似锦，一路繁华">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          读书笔记|图解机器学习算法
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-10-15 16:31:01" itemprop="dateCreated datePublished" datetime="2021-10-15T16:31:01+08:00">2021-10-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="图解机器学习算法"><a href="#图解机器学习算法" class="headerlink" title="图解机器学习算法"></a>图解机器学习算法</h1><p>作者：秋庭伸也</p>
<p>Python:3.7</p>
<p>scikit-learn:0.20.3</p>
<p>机器学习</p>
<ul>
<li>有监督学习<ul>
<li>分类(二元分类、多元分类）：逻辑回归， 支持向量机 ，支持向量机（核方法），朴素贝叶斯，随机森林，神经网络，KNN</li>
<li>回归：线性回归，正则化，支持向量机，支持向量机（核方法），随机森林，神经网络，KNN</li>
</ul>
</li>
<li>无监督学习<ul>
<li>降维：PCA、LSA、NMF、LDA、LLE、t-SNE</li>
<li>聚类：k-means、混合高斯模型</li>
</ul>
</li>
<li>强化学习</li>
</ul>
<span id="more"></span>

<h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h5 id="图型绘制"><a href="#图型绘制" class="headerlink" title="图型绘制"></a>图型绘制</h5><p>散点图：scatter</p>
<p>直方图：hist</p>
<p>柱状图：bar</p>
<p>折线图：plot</p>
<p>箱型图：boxplot</p>
<h5 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h5><p>相关系数：corr</p>
<p>统计信息：describe</p>
<p>散点图矩阵：scatter_matrix</p>
<h2 id="有监督学习"><a href="#有监督学习" class="headerlink" title="有监督学习"></a>有监督学习</h2><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>一元回归：y = w<del>0</del>+w<del>1</del>*x<del>1</del></p>
<p>多元回归：y = w<del>0</del>+w<del>1</del>*x<del>1</del>+w<del>2</del>*x<del>2</del></p>
<p>多项式回归：y = w<del>0</del>+w<del>1</del>*x<del>1</del>+w<del>2</del>*x^2^<del>1</del></p>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>超参数α</p>
<p>岭回归Ridge</p>
<p>Lasso回归</p>
<h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><p>二分类sigmoid</p>
<p>多分类softmax</p>
<p>np.r_</p>
<p>np.random.normal</p>
<p>model.predict_proba</p>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><p>间隔最大化</p>
<p>线性支持向量机：处理二分类</p>
<p>软间隔，超参数</p>
<p>支持向量：间隔内侧、间隔上 数据</p>
<p>网格搜索，随即搜索</p>
<p>make_blobs</p>
<h3 id="支持向量机（核方法）SVC"><a href="#支持向量机（核方法）SVC" class="headerlink" title="支持向量机（核方法）SVC"></a>支持向量机（核方法）SVC</h3><p>高维空间使用支持向量机学习决策边界 ，然后投影到原始特征形成的向量空间上，得到决策边界</p>
<p>通过核函数，核方法可以使用在高维空间中学习到的决策边界，无需构建具体的线性分离的高维空间。</p>
<p>不宜直接使用非线性核函数，应先使用线性核函数进行分析，以了解数据。</p>
<h3 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h3><p>常用于自然语言分类问题</p>
<p>BoW（Bag of Words）词袋  </p>
<p>计算两种概率：</p>
<p>1.每个标签出现的概率</p>
<p>2.在各标签下，每个单词出现的条件概率</p>
<p>平滑：在没有出现单词的位置也分配小的概率值</p>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><h5 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h5><p>不纯度，基尼指数，加权平均基尼指数</p>
<p>1.计算某个区域的所有特征值和候选分割的不纯度</p>
<p>2.以分割时不纯度减少最多的分割方式分割区域</p>
<p>3.对于分割后的区域重复1，2步骤</p>
<h5 id="随机森林-1"><a href="#随机森林-1" class="headerlink" title="随机森林"></a>随机森林</h5><p>Bootstrap方法以及随机选取特征值方法</p>
<h5 id="特征重要度"><a href="#特征重要度" class="headerlink" title="特征重要度"></a>特征重要度</h5><p>对随机森林的所有决策树求在以某个特征分割时的不纯度并取平均值</p>
<h3 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h3><p>输入层，中间层，输出层</p>
<h5 id="简单感知机"><a href="#简单感知机" class="headerlink" title="简单感知机"></a>简单感知机</h5><h5 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h5><p>早停法 防止过拟合</p>
<h3 id="KNN（K近邻）"><a href="#KNN（K近邻）" class="headerlink" title="KNN（K近邻）"></a>KNN（K近邻）</h3><p>1.计算输入数据与训练数据之间的距离。</p>
<p>2.得到距离输入数据最近的k个训练数据。</p>
<p>3.对训练数据的标签进行多数表决，将结果作为分类结果。</p>
<p>数据量小，维度小 适合</p>
<h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><h3 id="PCA主成分分析"><a href="#PCA主成分分析" class="headerlink" title="PCA主成分分析"></a>PCA主成分分析</h3><p>具有相关性的数据</p>
<p>PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身是密切相关的。</p>
<p>其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第1,2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。</p>
<p>思考：我们如何得到这些包含最大差异性的主成分方向呢？</p>
<p>答案：事实上，通过计算数据矩阵的协方差矩阵，然后得到协方差矩阵的特征值特征向量，选择特征值最大(即方差最大)的k个特征所对应的特征向量组成的矩阵。这样就可以将数据矩阵转换到新的空间当中，实现数据特征的降维。</p>
<p>由于得到协方差矩阵的特征值特征向量有两种方法：特征值分解协方差矩阵、奇异值分解协方差矩阵，所以PCA算法有两种实现方法：基于特征值分解协方差矩阵实现PCA算法、基于SVD分解协方差矩阵实现PCA算法。</p>
<p>降维是指在保留数据特征的前提下，以少量的变量表示有许多变量的数据，有助于降低多变量数据分析的复杂度。</p>
<p>用低维变量表示高维空间的数据，低维的轴叫做主成分。</p>
<h5 id="方向"><a href="#方向" class="headerlink" title="方向"></a>方向</h5><p>由构成新变量时对象数据变量的权重决定</p>
<h5 id="重要度"><a href="#重要度" class="headerlink" title="重要度"></a>重要度</h5><p>与变量偏差有关</p>
<h5 id="主成分得分"><a href="#主成分得分" class="headerlink" title="主成分得分"></a>主成分得分</h5><p>第一主成分，第二主成分</p>
<h5 id><a href="#" class="headerlink" title></a></h5><p>1.计算协方差矩阵</p>
<p>2对协方差矩阵求解特征值问题，求出特征向量和特征值</p>
<p>3.以数据表示各主成分方向。</p>
<p>特征值，特征向量</p>
<h3 id="LSA潜在语义分析（LSI）"><a href="#LSA潜在语义分析（LSI）" class="headerlink" title="LSA潜在语义分析（LSI）"></a>LSA潜在语义分析（LSI）</h3><p>从大量文本数据中找出单词之间的潜在关联性</p>
<p>潜在语义空间</p>
<p>矩阵分解</p>
<p>主要的问题有：<br>　　　　1） SVD计算非常的耗时，尤其是我们的文本处理，词和文本数都是非常大的，对于这样的高维度矩阵做奇异值分解是非常难的。<br>　　　　2） 主题值的选取对结果的影响非常大，很难选择合适的k值。<br>　　　　3） LSI得到的不是一个概率模型，缺乏统计基础，结果难以直观的解释。</p>
<h3 id="NMF非负矩阵分解"><a href="#NMF非负矩阵分解" class="headerlink" title="NMF非负矩阵分解"></a>NMF非负矩阵分解</h3><p>输入数据和输出数据的值都是非负的</p>
<p>没有“潜在语义空间的每一个维度都是正交的”这一约束条件</p>
<p>优点：可解释性强</p>
<p>V （n×d)= W(n×r)*H(r×d)</p>
<p>将W和H初始化为正值</p>
<p>将H视为常数，更新W</p>
<p>将W视为常数，更新H</p>
<p>当W和H收敛时，停止运算</p>
<h3 id="LDA隐含狄利克雷分布"><a href="#LDA隐含狄利克雷分布" class="headerlink" title="LDA隐含狄利克雷分布"></a>LDA隐含狄利克雷分布</h3><p>词袋模型</p>
<p>文本的主题分布</p>
<p>主题的单词分布</p>
<p>1.基于文本的主题分布为单词分配主题</p>
<p>2.基于分配的主题的单词分布确定单词</p>
<p>3.对所有文本中包含的单词执行步骤1和步骤2的操作。</p>
<h5 id="LDA算法步骤"><a href="#LDA算法步骤" class="headerlink" title="LDA算法步骤"></a>LDA算法步骤</h5><p>1.为各文本的单词随机分配主题</p>
<p>2.基于为单词分配的主题，计算每个文本的主题概率</p>
<p>3.基于为单词分配的主题，计算每个主题的单词概率</p>
<p>4.计算步骤2和步骤3中的概率的乘积，基于得到的概率，再次为各文本的单词分配主题。</p>
<p>5.重复步骤2~步骤4的计算，直到收敛。</p>
<h3 id="K-means算法"><a href="#K-means算法" class="headerlink" title="K-means算法"></a>K-means算法</h3><p>1.从数据点随机选择数量与簇的数量相同的数据点，作为这些簇的重心。</p>
<p>2.计算数据点与各个重心之间的距离，并将最近的重心所在的簇作为该数据点所属的簇。</p>
<p>3.计算每个簇的数据点的平均值，作为新的重心。</p>
<p>4.重复2，3，继续计算，直到所有数据点不改变所属的簇，或者达到最大计算步数。</p>
<h5 id="Elbow方法"><a href="#Elbow方法" class="headerlink" title="Elbow方法"></a>Elbow方法</h5><p>确定合适的簇的数量</p>
<h5 id="簇内平方和WCSS"><a href="#簇内平方和WCSS" class="headerlink" title="簇内平方和WCSS"></a>簇内平方和WCSS</h5><p>判断聚类结果的好坏</p>
<p>随着簇的数量增加，WCSS会变小</p>
<p>指对所有簇计算其所属的数据点与簇的重心之间距离的平方和，并将它们相加得到的值。值越小，说明聚类结果越好。</p>
<h3 id="混合高斯分布"><a href="#混合高斯分布" class="headerlink" title="混合高斯分布"></a>混合高斯分布</h3><h5 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h5><p>高斯分布（Gaussian distribution）有时也被称为正态分布（normal distribution），是一种在自然界大量的存在的、最为常见的分布形式。</p>
<p>1.初始化参数（各高斯分布的均值和方差）</p>
<p>2.对每个类别计算数据点的权重。</p>
<p>3.根据步骤2中计算出的权重重新计算参数。</p>
<p>4.重复2，3直到通过3更新前后的每个均值的变化足够小。</p>
<p>高斯分布：椭圆形分布数据</p>
<p>K-means：圆形分布数据</p>
<h3 id="LLE局部线性嵌入"><a href="#LLE局部线性嵌入" class="headerlink" title="LLE局部线性嵌入"></a>LLE局部线性嵌入</h3><p>流形学习</p>
<p>流形：可以将局部看作没有弯曲的空间。</p>
<p>在D维空间存在一个d维空间结构（d&lt;D)</p>
<p>1.找到数据点x<del>i</del>的近邻点(k个)。</p>
<p>2.求出能用k个近邻点的线性组合表示x<del>i</del>的权重w<del>ij</del>。</p>
<p>3.使用权重w<del>ij</del>计算低维（d维）的y<del>i</del>。</p>
<h3 id="t-SNE-t分布随机邻域嵌入"><a href="#t-SNE-t分布随机邻域嵌入" class="headerlink" title="t-SNE t分布随机邻域嵌入"></a>t-SNE t分布随机邻域嵌入</h3><p>将高维复杂数据降维为二维（或三维）算法，用于低维空间的可视化</p>
<p>在降维时使用自由度为1的t分布</p>
<p>原本很近的结构在低维空间更近，原本较远的结构变得更远。</p>
<p>1.对于所有的组i、j，使用高斯分布来表示x<del>i</del>和x<del>j</del>的相似度。</p>
<p>2.在低维空间中随机配置与x<del>i</del>相同数量的点y<del>i</del>，对于所有的组i、j，使用t分布表示y<del>i</del>和y<del>j</del>的相似度。</p>
<p>3.更新数据点y<del>i</del>，使得步骤1和步骤2中定义的相似度分布尽可能的相似。</p>
<p>4.重复步骤3，直到达到收敛条件。</p>
<h2 id="评估方法和各种数据处理"><a href="#评估方法和各种数据处理" class="headerlink" title="评估方法和各种数据处理"></a>评估方法和各种数据处理</h2><p>分类问题：混淆矩阵、正确率、精确率、召回率、F值、AUC</p>
<p>回归问题：均方误差、决定系数</p>
<h3 id="分类问题评估方法"><a href="#分类问题评估方法" class="headerlink" title="分类问题评估方法"></a>分类问题评估方法</h3><p>准确率：预测正确的结果占总预测结果的比例。accuracy_score(y,y_pred)</p>
<p>精确率：在所有被预测为阳性的数据中，被正确预测为阳性的数据所占的比例。precision_score(y,y_pred)</p>
<p>召回率：在实际为阳性的数据中，被正确预测为阳性的数据所占的比例。recall_score(y,y_pred)</p>
<p>F值：综合反映精确率，召回率两个趋势的指标。f1_score(y,y_pred)。精确率，召回率此消彼长，如果这俩个指标同等重要，可以观察F值。</p>
<p>预测概率：predict_proba，输出每个数据被分类为各标签的概率</p>
<p>(model_lor.predict_proba(X)[: , 1]&gt;0.1).astype(np.int)</p>
<p>应对数据不均衡问题指标：AUC，AUC指的是ROC曲线下的面积。roc_auc_score(y,probas[:, 1])</p>
<h3 id="回归问题评估方法"><a href="#回归问题评估方法" class="headerlink" title="回归问题评估方法"></a>回归问题评估方法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import load_boston</span><br><span class="line"></span><br><span class="line">data = load_boston()</span><br><span class="line">#X x1取到的都是 二维数组</span><br><span class="line">X = data.data[:, [5, ]]</span><br><span class="line">x1 = data.data[:, [5]]</span><br><span class="line">#x2 取到的 是 一维数组</span><br><span class="line">x2 = data.data[:, 5]</span><br></pre></td></tr></table></figure>

<p>均方误差MSE，mean_squared_error(y,y_pred) 计算所有预测值与数据之间的误差的平方，并取平方的平均值</p>
<p>决定系数R^2^：越接近1说明预测越好 r2_score(y,y_pred)</p>
<h3 id="防止过拟合"><a href="#防止过拟合" class="headerlink" title="防止过拟合"></a>防止过拟合</h3><p>增加训练数据，减少特征值，正则化，Early Stopping ，集成学习</p>
<p>将数据分为训练数据和验证数据，train_test_split(X,y,test_size =0.3)</p>
<h5 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cv = KFold(5,shuffle = true)</span><br><span class="line">model_rfc_1 = RandomForestClassifier()</span><br><span class="line">cross_val_score(model_rfc_1,X,y,cv=cv,scoring=&#x27;accuracy&#x27;)</span><br></pre></td></tr></table></figure>

<h5 id="搜索超参数"><a href="#搜索超参数" class="headerlink" title="搜索超参数"></a>搜索超参数</h5><p>网格搜索：一种自动搜索超参数方法</p>
<p>GridSearchCV(model,param_grid,cv=cv,scoring=’accuracy’)</p>
<h3 id="文本数据处理"><a href="#文本数据处理" class="headerlink" title="文本数据处理"></a>文本数据处理</h3><p>1.基于单词出现次数的转换</p>
<p>2.基于tf-idf的转换</p>
<p>tf词频，idf逆文本频率指数，tf是单词在文本中出现的频率，idf是一个包含该单词的文本越多，值就越小的值。</p>
<h3 id="图像数据处理"><a href="#图像数据处理" class="headerlink" title="图像数据处理"></a>图像数据处理</h3><p>1.直接将像素信息作为数值使用</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" rel="tag"># 读书笔记</a>
              <a href="/tags/ML/" rel="tag"># ML</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/09/15/dian-zi-shu-yi-ji-bi-ji/zong-shu-lei-bi-ji/" rel="prev" title="综述|研究方向预备知识总结">
                  <i class="fa fa-chevron-left"></i> 综述|研究方向预备知识总结
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/10/26/leetcode/1-100/15.san-shu-zhi-he/" rel="next" title="Leetcode-15.三数之和">
                  Leetcode-15.三数之和 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">fanko</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
